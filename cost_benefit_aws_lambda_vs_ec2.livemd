<!-- livebook:{"persist_outputs":true} -->

# Cost-Benefit AWS Lambda vs EC2

```elixir
# Setup
Mix.install([
  {:vega_lite, "~> 0.1.6"},
  {:kino_vega_lite, "~> 0.1.11"}
])
```

## Overview

At some point of time you will find yourself asking the question: When should I stop using a serverless compute service and start thinking about a virtual machine in the cloud? - I am using AWS services as example because are the ones I have more familiarity with.

This is our scenario (assumptions):

* We have a system that is constantly executing jobs on a daily basis.
* The system is intended to keep running for less than a year.
* The jobs are critical and cannot be interrupted.
* We don't know how long in average each job takes to complete.
* For simplicity, we assume that Lambda and EC2 offer equivalent compute performance, meaning each job takes the same amount of time to complete on either. While this isn't true in practice (as Lambda and EC2 instances have different performance characteristics), it helps streamline our cost-benefit analysis.

The goal is to know which service brings us the best cost-benefit depending on the computation load of our system.

To calculate the cost-benefit we can start by asking the question: How many jobs can the cheapest EC2 instance handle compared to the cost of running the same number of jobs in a Lambda?

Let's break this down.

## 1. Setup

### Average Job Duration

Based on our assumptions we don't know how long in average each job takes to complete. So, we must define our lower and upper bounds.

Arbitrarily, I will choose `1 ms/job` as lower bound. However, the upper bound must be `900,000 ms/job` (15 minutes) which is the maximum [Lambda timeout](https://docs.aws.amazon.com/lambda/latest/dg/configuration-timeout.html) meaning that a lambda cannot run jobs longer than 15 minutes.

```elixir
average_job_durations_ms = 1..900_000
```

### EC2 Setup

#### Settings

Region: `us-east-1`, Contract: `on-demand`, Instance Name: `t4g.nano`, Instance Type: `General Purpose`, Operating System: `linux`, Memory: `0.5gb`, vCPU: `2`.

[Price](https://aws.amazon.com/ec2/pricing/on-demand/): on-demand hourly: `0.0042 $/hour`.

#### Cost Calculation

Based on our assumptions the EC2 instance need to keep running 24/7 for less than a year, and the jobs are critical. Choosing an on-demand instance is a great start. Now, the monthly cost can be easily calculated using AWS pricing data with the following formula: `monthly_cost = price_per_hour * hours_per_day * days_per_month`.

```elixir
defmodule EC2 do
  def settings do
    %{
      memory_gb: 0.5,
      v_cpu: 2,
      hourly_price: 0.0042
    }
  end

  def get_monthly_cost() do
    ec2_settings = settings()
    hours_day = 24
    days_month = 30
    
    Float.round(ec2_settings.hourly_price * hours_day * days_month, 2)
  end
end

EC2.settings()
```

#### Lambda Setup

#### Setup

Region: `us-east-1`, Architecture: `x86`, Memory: `128 mb`, Ephemeral Storage: `512 mb`.

[Price](https://aws.amazon.com/lambda/pricing/): request price: `0.0000002 request`, execution price: `0.0000166667 gb/second`.

Where the request price is the number of jobs you request a lambda to execute and the execution price is the time it takes to complete the job.

#### Cost Calculation

Assuming that cold starts do not impact performance and that jobs nearing the timeout limit complete without unexpected interruptions, the function `calculate_monthly_costs()` estimates the total monthly cost of running a Lambda function. This calculation is based on two key inputs:

* The total number of job requests per month.
* The average execution time per job.

The function follows the same pricing model as outlined in the [Lambda Cost Calculator](https://calculator.aws/#/createCalculator/Lambda), taking into account compute time, request count, and ephemeral storage if applicable.

```elixir
defmodule Lambda do
  @type average_job_duration_ms :: integer()
  @type requests :: integer()
  @type cost :: float()
  @type cost_scenario :: {average_job_duration_ms, requests, cost}

  def settings do
    %{
      memory_mb: 128,
      ephemeral_storage_mb: 512,
      execution_price_gb_sec: 0.0000166667,
      request_price: 0.0000002,
      ephemeral_storage_price_gb: 0.0000000309,
    }
  end

  @spec calculate_monthly_costs(requests_month :: integer(), avg_request_duration_ms :: integer()) :: cost_scenario()
  def calculate_monthly_costs(requests_month, avg_request_duration_ms) do
    # Unit conversions
    mb_to_gb = 0.0009765625
    ms_to_s = 0.001

    # Free tiering
    free_compute_tier_gb_s = 400000
    free_request_tier = 1000000
    free_ephemeral_storage_tier_gb = 0.5

    # Lambda settings
    lambda_settings = settings()

    # Compute price calculations
    memory_allocated = lambda_settings.memory_mb * mb_to_gb
    total_compute_s = requests_month * avg_request_duration_ms * ms_to_s
    billable_compute = max(memory_allocated * total_compute_s - free_compute_tier_gb_s, 0)
    compute_cost = billable_compute * lambda_settings.execution_price_gb_sec

    # Request price calculations
    billable_requests = max(requests_month - free_request_tier, 0)
    request_cost = billable_requests * lambda_settings.request_price

    # Ephemeral storage calculations
    ephemeral_storage_allocated = lambda_settings.ephemeral_storage_mb * mb_to_gb
    billable_ephemeral_storage = max(ephemeral_storage_allocated - free_ephemeral_storage_tier_gb, 0)
    ephemeral_storage_cost = billable_ephemeral_storage * total_compute_s * lambda_settings.ephemeral_storage_price_gb

    # Total cost
    total_cost = compute_cost + request_cost + ephemeral_storage_cost
    Float.round(total_cost, 2)
  end
end

Lambda.settings()
```

## 2. Cost Calculations

To calculate EC2 and Lambda costs we will use different scenarios.

A scenario represents a single possible configuration of the maximum capacity for a workload that the EC2 instance can handle and its associated cost. Specifically, it defines:

The cost of executing a given number of jobs, where each job takes a certain average time to complete. Each scenario is encapsulated as a map in the form:

`%{
  average_job_duration_ms: <ajd>,
  jobs_month: <jm>,
  cost: <c>
}`.

<!-- livebook:{"break_markdown":true} -->

### Scenarios

```elixir
alias VegaLite, as: Vl

ms_month = :timer.hours(24 * 30)
ec2_settings = EC2.settings()

scenarios = Enum.map(average_job_durations_ms, fn ajd_ms ->
    jobs_month = round(ms_month / ajd_ms * ec2_settings.v_cpu)

    %{
      average_job_duration_ms: ajd_ms,
      jobs_month: jobs_month,
      cost: nil
    }
  end)
```

```elixir
Vl.new(width: 400, height: 400, title: "Cost Scenarios")
|> Vl.data_from_values(scenarios)
|> Vl.concat(
  [
    # Chart 1 unclipped
    Vl.new(title: "(Unclipped)")
    |> Vl.mark(:line, tooltip: [content: "data"])
    |> Vl.encode_field(
      :x, "average_job_duration_ms",
      scale: [type: "pow"],
      axis: [title: "Average Job Durations (ms)"]
    )
    |> Vl.encode_field(
      :y, "jobs_month",
      scale: [type: "pow"],
      title: "Jobs per Month"
    ),
    # Chart 2 clipped
    Vl.new(title: "(Clipped)")
    |> Vl.mark(:line, clip: true, tooltip: [content: "data"])
    |> Vl.encode_field(
      :x, "average_job_duration_ms",
      scale: [type: "pow", domain: [0, 400000]],
      axis: [title: "Average Job Durations (ms)"]
    )
    |> Vl.encode_field(
      :y, "jobs_month",
      scale: [type: "pow", domain: [0, 1000000]],
      title: "Jobs per Month"
    )
  ],
  :horizontal
)
```

From the charts we can tell the following:

* `Inverse Relationship` Between Job Duration and Job Throughput: longer jobs translate into fewer total jobs.
* The `max` amount of jobs is 5,184,000,000 jobs/month when each job takes 1 ms to complete.
* The `min` amount of jobs is 5,760 jobs/month when each job takes 900,000 ms to complete.
* The curve shows a `decreasing rate of change` between ~400,000 and ~200,000 jobs/month, meaning that while job throughput continues to decline as duration increases, the decline becomes less steep. This suggests diminishing returns and indicates that the system is approaching a lower bound in throughput.
* In the range between ~5,000,000,000 and ~400,000 jobs/month, the curve exhibits a `steep negative slope, indicating a high sensitivity of job throughput to changes in duration`. In this region, small increases in average job duration lead to substantial decreases in throughput.
* When the average job duration exceeds ~200,000ms, the `curve begins to flatten, indicating a reduced sensitivity of throughput to duration`. In this region, further increases in job duration result in only marginal decreases in job throughput.

<!-- livebook:{"break_markdown":true} -->

### EC2 Cost

```elixir
ec2_cost_scenarios = Enum.map(scenarios, fn scenario ->
    Map.put(scenario, :cost, EC2.get_monthly_cost())
  end)
```

```elixir
Vl.new(width: 400, height: 400, title: "Cost Scenarios (Clipped)")
|> Vl.data_from_values(ec2_cost_scenarios)
|> Vl.encode_field(:x, "average_job_duration_ms",
    scale: [type: "pow", domain: [0, 400000]],
    axis: [title: "Average Job Durations (ms)"]
)
|> Vl.layers([
  Vl.new()
  |> Vl.mark(:line, color: "blue", clip: true, tooltip: [content: "data"])
  |> Vl.encode_field(:y, "jobs_month",
    scale: [type: "pow", domain: [0, 1000000]],
    title: "Jobs per Month",
    axis: [title_color: "blue"]
  ),
  Vl.new()
  |> Vl.mark(:line, color: "green", clip: true, tooltip: [content: "data"])
  |> Vl.encode_field(:y, "cost",
    title: "Monthly Cost (USD)",
    axis: [title_color: "green"]
  )
])
|> Vl.resolve(:scale, y: :independent)
```

Looking at the chart we can tell the following:

* The EC2 instance can support `5,184,000,000 jobs/month` when each job takes `1 ms` and `5,760 jobs/month` when each job takes `900,000 ms` (15 minutes) to complete. All for the same fixed cost of `3.02 $/month`. In other words, billing is based on provisioned time, not actual usage or workload intensity.

<!-- livebook:{"break_markdown":true} -->

### Lambda Cost

```elixir
lambda_cost_scenarios = Enum.map(scenarios, fn %{average_job_duration_ms: ajd, jobs_month: jm} = scenario ->
    Map.put(scenario, :cost, Lambda.calculate_monthly_costs(jm, ajd))
  end)
```

```elixir
Vl.new(width: 400, height: 400)
|> Vl.data_from_values(lambda_cost_scenarios)
|> Vl.concat(
  [
    # Chart 1 scenarios
    Vl.new(title: "Cost Scenarios")
    |> Vl.mark(:line, color: "blue", clip: true, tooltip: [content: "data"])
    |> Vl.encode_field(
      :x, "average_job_duration_ms",
      scale: [type: "pow", domain: [0, 400000]],
      axis: [title: "Average Job Durations (ms)"]
    )
    |> Vl.encode_field(
      :y, "jobs_month",
      scale: [type: "pow", domain: [0, 1000000]],
      title: "Jobs per Month",
      axis: [title_color: "blue"]
    ),
    # Chart 2 costs
    Vl.new(title: "Cost per Scenario")
    |> Vl.mark(:line, color: "green", clip: true, tooltip: [content: "data"])
    |> Vl.encode_field(
      :x, "average_job_duration_ms",
      scale: [type: "log"],
      axis: [title: "Cost Scenario"]
    )
    |> Vl.encode_field(
      :y, "cost",
      scale: [type: "log"],
      title: "Monthly Cost (USD)",
      axis: [title_color: "green"]
    )
  ],
  :horizontal
)
```

WIP

Looking at the charts we can tell the following:

* The Lambda can support `5,184,000,000 jobs/month` when each job takes `1 ms` to complete at a price of `1040.73 $/month`
* The Lambda can support `5,760 jobs/month` when each job takes `900,000 ms` (15 minutes) to complete at a price of `4.13 $/month`.
* The cost decreas more sensible when there are a lot of sort running jobs.
* The lowest price `4.13 $/month` can be achieved on different scenarios.

<!-- livebook:{"break_markdown":true} -->

### EC2 vs Lambda Costs

```elixir
comparison_cost_scenarios = Enum.flat_map(lambda_cost_scenarios, fn scenario ->
    updated_scenario = Map.put(scenario, :service, "Lambda")
    
    new_scenario = 
      scenario
      |> Map.put(:cost, EC2.get_monthly_cost())
      |> Map.put(:service, "EC2")

    [updated_scenario, new_scenario]
  end)
```

```elixir
Vl.new(width: 400, height: 400, title: "EC2 vs Lambda Cost")
|> Vl.data_from_values(comparison_cost_scenarios)
|> Vl.concat(
  [
    # Chart 1
    Vl.new(title: "(Unclipped)")
    |> Vl.mark(:line, clip: true, tooltip: [content: "data"])
    |> Vl.encode_field(
      :x, "average_job_duration_ms",
      type: :quantitative,
      axis: [title: "Cost Scenario"]
    )
    |> Vl.encode_field(
      :y, "cost",
      type: :quantitative,
      title: "Service Cost"
    )
    |> Vl.encode_field(:color, "service", type: :nominal),
    # Chart 2
    Vl.new(title: "(Clipped)")
    |> Vl.mark(:line, clip: true, tooltip: [content: "data"])
    |> Vl.encode_field(
      :x, "average_job_duration_ms",
      type: :quantitative,
      scale: [type: "pow", domain: [0, 1000]],
      axis: [title: "Cost Scenario"]
    )
    |> Vl.encode_field(
      :y, "cost",
      scale: [domain: [0, 100]],
      type: :quantitative,
      title: "Service Cost"
    )
    |> Vl.encode_field(:color, "service", type: :nominal)
  ],
  :horizontal
)
```

WIP

## 3. Final Thoughts

WIP

* Computational Capacity Bound: Since we are simulating a fixed compute resource the maximum job throughput is constrained by job duration and resource count.
